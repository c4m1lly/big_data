{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87R_uiuEGbzE"
      },
      "source": [
        "## Upload do arquivo `imdb-reviews-pt-br.csv` para dentro do Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0-DuDa3GbzE",
        "outputId": "bf0b0eec-474c-4f44-c405-264ac9592504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-05 16:15:11--  https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49549692 (47M) [application/zip]\n",
            "Saving to: ‘imdb-reviews-pt-br.zip’\n",
            "\n",
            "imdb-reviews-pt-br. 100%[===================>]  47.25M   183MB/s    in 0.3s    \n",
            "\n",
            "2024-11-05 16:15:12 (183 MB/s) - ‘imdb-reviews-pt-br.zip’ saved [49549692/49549692]\n",
            "\n",
            "Archive:  imdb-reviews-pt-br.zip\n",
            "  inflating: imdb-reviews-pt-br.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip -O imdb-reviews-pt-br.zip\n",
        "!unzip imdb-reviews-pt-br.zip\n",
        "!rm imdb-reviews-pt-br.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cApg4jFQGbzF"
      },
      "source": [
        "## Instalação manual das dependências para uso do pyspark no Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d83AkwYGbzF",
        "outputId": "677be15d-be9e-4d68-c1c0-2c278b4b44df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Zak8icGbzG"
      },
      "source": [
        "## Importar, instanciar e criar a SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PTlw96Q2GbzG"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "appName = \"PySpark Trabalho de Big Data\"\n",
        "master = \"local\"\n",
        "\n",
        "spark = SparkSession.builder.appName(appName).master(master).getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clnytXdEGbzG"
      },
      "source": [
        "## Criar spark dataframe do CSV utilizando o método read.csv do spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hZ0hiLnBGbzG"
      },
      "outputs": [],
      "source": [
        "imdb_df = spark.read.csv('imdb-reviews-pt-br.csv',\n",
        "                         header=True,\n",
        "                         quote=\"\\\"\",\n",
        "                         escape=\"\\\"\",\n",
        "                         encoding=\"UTF-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HSg6WWzGbzH"
      },
      "source": [
        "# Questão 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj8UkNqfGbzH"
      },
      "source": [
        "## Criar funções de MAP:\n",
        "- Criar função para mapear o \"sentiment\" como chave e o \"id\" como valor do tipo inteiro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B39sh9n8GbzH",
        "outputId": "4a355948-ff5f-405a-f1dd-db0e03e0caa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O valor da soma de todos os IDs dos filmes classificados como negativos é: 314\n"
          ]
        }
      ],
      "source": [
        "# Função para mapear \"sentiment\" como chave e \"id\" como valor do tipo inteiro\n",
        "def map1(x):\n",
        "    return (x['sentiment'], int(x['id']))\n",
        "\n",
        "# Dados de exemplo\n",
        "data = [\n",
        "    {'sentiment': 'positive', 'id': '101'},\n",
        "    {'sentiment': 'negative', 'id': '102'},\n",
        "    {'sentiment': 'negative', 'id': '105'},\n",
        "    {'sentiment': 'neutral', 'id': '103'},\n",
        "    {'sentiment': 'negative', 'id': '107'}\n",
        "]\n",
        "\n",
        "# Mapeia os dados\n",
        "mapped_data = list(map(map1, data))\n",
        "\n",
        "# Filtra apenas os elementos com \"sentiment\" negativo e soma os IDs\n",
        "soma_ids_negativos = sum(id_value for sentiment, id_value in mapped_data if sentiment == 'negative')\n",
        "\n",
        "print(f\"O valor da soma de todos os IDs dos filmes classificados como negativos é: {soma_ids_negativos}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kzz7CG-GbzH"
      },
      "source": [
        "## Cria funções de REDUCE:\n",
        "\n",
        "- Criar função de reduce para somar os IDs por \"sentiment\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nph8GhcmGbzK",
        "outputId": "71f19559-42b1-43c5-cdd7-1d0d1292bda5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'positive': 4, 'negative': 3, 'neutral': 1}\n"
          ]
        }
      ],
      "source": [
        "def reduceByKey1(x, y):\n",
        "    # x e y são os IDs que precisam ser somados\n",
        "    return x + y\n",
        "\n",
        "data = [('positive', 1), ('negative', 2), ('positive', 3), ('neutral', 1), ('negative', 1)]\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# Inicializa um dicionário para armazenar a soma dos IDs por sentimento\n",
        "sentiment_sums = defaultdict(int)\n",
        "\n",
        "# Percorre os dados e acumula os IDs\n",
        "for sentiment, id in data:\n",
        "    sentiment_sums[sentiment] = reduceByKey1(sentiment_sums[sentiment], id)\n",
        "\n",
        "# Exibe o resultado\n",
        "print(dict(sentiment_sums))  # {'positive': 4, 'negative': 3, 'neutral': 1}\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAuatGL8GbzK"
      },
      "source": [
        "## Aplicação do map/reduce e visualização do resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySVIb2oYGbzK",
        "outputId": "dbfc30a2-0e76-4845-88cb-26da630fcf3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(sentiment='positive', total_id=4)\n",
            "Row(sentiment='neutral', total_id=1)\n",
            "Row(sentiment='negative', total_id=3)\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MapReduce Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Exemplo de dados\n",
        "data = [\n",
        "    ('positive', 1),\n",
        "    ('negative', 2),\n",
        "    ('positive', 3),\n",
        "    ('neutral', 1),\n",
        "    ('negative', 1)\n",
        "]\n",
        "\n",
        "# Criação do DataFrame\n",
        "df = spark.createDataFrame(data, ['sentiment', 'id'])\n",
        "\n",
        "# Aplicando MapReduce: agrupando por 'sentiment' e somando os IDs\n",
        "result = df.groupBy('sentiment').agg(F.sum('id').alias('total_id'))\n",
        "\n",
        "# Coletando os resultados\n",
        "collected_results = result.collect()\n",
        "\n",
        "# Exibindo os resultados\n",
        "for row in collected_results:\n",
        "    print(row)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q18UlPvJGbzL"
      },
      "source": [
        "# Questão 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPSTua20GbzL"
      },
      "source": [
        "## Criar funções de MAP:\n",
        "- Criar função para mapear o \"sentiment\" como chave e uma tupla com a soma das palavras de cada texto como valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QYAZziKGbzL",
        "outputId": "532686da-6692-47ba-d521-d07013f03cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('positive', (4,)), ('negative', (6,)), ('neutral', (5,)), ('positive', (3,))]\n"
          ]
        }
      ],
      "source": [
        "def map2(x):\n",
        "    # x é uma tupla no formato (sentiment, text)\n",
        "    sentiment = x[0]  # O sentimento é o primeiro elemento\n",
        "    text = x[1]      # O texto é o segundo elemento\n",
        "\n",
        "    # Contamos o número de palavras no texto\n",
        "    word_count = len(text.split())  # Divide o texto em palavras e conta\n",
        "\n",
        "    # Retorna uma tupla com o sentimento e a contagem de palavras\n",
        "    return (sentiment, (word_count,))\n",
        "\n",
        "# Exemplo de dados\n",
        "data = [\n",
        "    ('positive', 'I love this product!'),\n",
        "    ('negative', 'This is the worst experience ever.'),\n",
        "    ('neutral', 'It was okay, nothing special.'),\n",
        "    ('positive', 'Absolutely fantastic service!')\n",
        "]\n",
        "\n",
        "# Aplicando a função map2 a cada elemento dos dados\n",
        "mapped_results = [map2(item) for item in data]\n",
        "\n",
        "# Exibindo os resultados mapeados\n",
        "print(mapped_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFCqo8ahGbzL"
      },
      "source": [
        "## Cria funções de REDUCE:\n",
        "\n",
        "- Criar função de reduce para somar o numero de palavras de cada texto português e inglês por \"sentiment\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whQ2n_cAGbzL",
        "outputId": "a1d6b102-a87c-4d46-c638-09dffd3e0dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'negativo': 15, 'positivo': 9}\n"
          ]
        }
      ],
      "source": [
        "def reduceByKey2(x, y):\n",
        "    # Conta o número de palavras no texto x\n",
        "    palavras_x = len(x.split())\n",
        "\n",
        "    # Conta o número de palavras no texto y\n",
        "    palavras_y = len(y.split())\n",
        "\n",
        "    # Retorna a soma das palavras de ambos os textos\n",
        "    return palavras_x + palavras_y\n",
        "\n",
        "# Dados de exemplo, onde cada tupla é ('sentimento', 'texto')\n",
        "dados = [\n",
        "    (\"positivo\", \"Eu amo aprender novas coisas.\"),\n",
        "    (\"negativo\", \"Eu detesto quando as coisas não dão certo.\"),\n",
        "    (\"positivo\", \"A vida é maravilhosa.\"),\n",
        "    (\"negativo\", \"Estou muito frustrado com o que aconteceu.\"),\n",
        "]\n",
        "\n",
        "# Agora vamos agrupar os dados por sentimento e aplicar o reduce\n",
        "from itertools import groupby\n",
        "from functools import reduce\n",
        "\n",
        "# Ordena os dados pela chave (sentimento)\n",
        "dados.sort(key=lambda x: x[0])  # Necessário para usar groupby corretamente\n",
        "\n",
        "# Agrupar os dados por sentimento\n",
        "resultados = {}\n",
        "for chave, grupo in groupby(dados, key=lambda x: x[0]):\n",
        "    textos = [item[1] for item in grupo]  # Coleta os textos associados ao sentimento\n",
        "    # Aplica a função de redução para contar o número total de palavras\n",
        "    total_palavras = reduce(reduceByKey2, textos)\n",
        "    resultados[chave] = total_palavras\n",
        "\n",
        "# Exibe o resultado\n",
        "print(resultados)\n",
        "\n",
        "dados = [\n",
        "    (\"positivo\", \"Eu amo aprender novas coisas.\"),\n",
        "    (\"negativo\", \"Eu detesto quando as coisas não dão certo.\"),\n",
        "    (\"positivo\", \"A vida é maravilhosa.\"),\n",
        "    (\"negativo\", \"Estou muito frustrado com o que aconteceu.\"),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw8DrRVvGbzL"
      },
      "source": [
        "## Aplicação do map/reduce e visualização do resultado\n",
        "\n",
        "1. Aplicar o map/reduce no seu dataframe spark e realizar o collect() ao final\n",
        "2. Selecionar os dados referentes aos textos negativos para realizar a subtração.\n",
        "3. Realizar a subtração das contagens de palavras dos textos negativos para obter o resultado final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCWlGHFZGbzL",
        "outputId": "084c3151-b0e0-4077-a910-b68bd14135a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------------------------------+\n",
            "|sentiment|text                                      |\n",
            "+---------+------------------------------------------+\n",
            "|positivo |Eu amo aprender novas coisas.             |\n",
            "|negativo |Eu detesto quando as coisas não dão certo.|\n",
            "|positivo |A vida é maravilhosa.                     |\n",
            "|negativo |Estou muito frustrado com o que aconteceu.|\n",
            "+---------+------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Iniciar a sessão do Spark\n",
        "spark = SparkSession.builder.appName(\"MapReduceTextExample\").getOrCreate()\n",
        "\n",
        "dados = [\n",
        "    (\"positivo\", \"Eu amo aprender novas coisas.\"),\n",
        "    (\"negativo\", \"Eu detesto quando as coisas não dão certo.\"),\n",
        "    (\"positivo\", \"A vida é maravilhosa.\"),\n",
        "    (\"negativo\", \"Estou muito frustrado com o que aconteceu.\"),\n",
        "]\n",
        "\n",
        "# Criar DataFrame do Spark\n",
        "df = spark.createDataFrame(dados, [\"sentiment\", \"text\"])\n",
        "\n",
        "# Exibir o DataFrame\n",
        "df.show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}