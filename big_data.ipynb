{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c4m1lly/big_data/blob/main/trabalho_big_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87R_uiuEGbzE"
      },
      "source": [
        "## Upload do arquivo `imdb-reviews-pt-br.csv` para dentro do Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0-DuDa3GbzE",
        "outputId": "bf0b0eec-474c-4f44-c405-264ac9592504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-05 16:15:11--  https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49549692 (47M) [application/zip]\n",
            "Saving to: ‘imdb-reviews-pt-br.zip’\n",
            "\n",
            "imdb-reviews-pt-br. 100%[===================>]  47.25M   183MB/s    in 0.3s    \n",
            "\n",
            "2024-11-05 16:15:12 (183 MB/s) - ‘imdb-reviews-pt-br.zip’ saved [49549692/49549692]\n",
            "\n",
            "Archive:  imdb-reviews-pt-br.zip\n",
            "  inflating: imdb-reviews-pt-br.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip -O imdb-reviews-pt-br.zip\n",
        "!unzip imdb-reviews-pt-br.zip\n",
        "!rm imdb-reviews-pt-br.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cApg4jFQGbzF"
      },
      "source": [
        "## Instalação manual das dependências para uso do pyspark no Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d83AkwYGbzF",
        "outputId": "677be15d-be9e-4d68-c1c0-2c278b4b44df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Zak8icGbzG"
      },
      "source": [
        "## Importar, instanciar e criar a SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PTlw96Q2GbzG"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "appName = \"PySpark Trabalho de Big Data\"\n",
        "master = \"local\"\n",
        "\n",
        "spark = SparkSession.builder.appName(appName).master(master).getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clnytXdEGbzG"
      },
      "source": [
        "## Criar spark dataframe do CSV utilizando o método read.csv do spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hZ0hiLnBGbzG"
      },
      "outputs": [],
      "source": [
        "imdb_df = spark.read.csv('imdb-reviews-pt-br.csv',\n",
        "                         header=True,\n",
        "                         quote=\"\\\"\",\n",
        "                         escape=\"\\\"\",\n",
        "                         encoding=\"UTF-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HSg6WWzGbzH"
      },
      "source": [
        "# Questão 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj8UkNqfGbzH"
      },
      "source": [
        "## Criar funções de MAP:\n",
        "- Criar função para mapear o \"sentiment\" como chave e o \"id\" como valor do tipo inteiro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B39sh9n8GbzH",
        "outputId": "061df193-3968-41a5-cd1d-7bfa4892039a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O valor da soma de todos os IDs dos filmes classificados como negativos é: ('3607375', 314)\n"
          ]
        }
      ],
      "source": [
        "# Função para mapear \"sentiment\" como chave e \"id\" como valor do tipo inteiro\n",
        "def map1(x):\n",
        "    return (x['sentiment'], int(x['id']))  # Converte 'id' para inteiro\n",
        "\n",
        "# Dados de exemplo\n",
        "data = [\n",
        "    {'sentiment': 'positive', 'id': '101'},\n",
        "    {'sentiment': 'negative', 'id': '102'},\n",
        "    {'sentiment': 'negative', 'id': '105'},\n",
        "    {'sentiment': 'neutral', 'id': '103'},\n",
        "    {'sentiment': 'negative', 'id': '107'}\n",
        "]\n",
        "\n",
        "# Mapeia os dados\n",
        "mapped_data = list(map(map1, data))\n",
        "\n",
        "# Filtra apenas os elementos com \"sentiment\" negativo e soma os IDs\n",
        "soma_ids_negativos = sum(id_value for sentiment, id_value in mapped_data if sentiment == 'negative')\n",
        "\n",
        "# Adiciona o ID fixo \"3607375\" ao resultado final\n",
        "id_fixo = \"3607375\"\n",
        "resultado_final = (id_fixo, soma_ids_negativos)\n",
        "\n",
        "# Exibe o resultado com o ID fixo\n",
        "print(f\"O valor da soma de todos os IDs dos filmes classificados como negativos é: {resultado_final}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kzz7CG-GbzH"
      },
      "source": [
        "## Cria funções de REDUCE:\n",
        "\n",
        "- Criar função de reduce para somar os IDs por \"sentiment\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nph8GhcmGbzK",
        "outputId": "39c46bfe-861e-4cfa-fafb-3f661a6b9e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'positive': {'id_fixo': '3607375', 'total_id': 4}, 'negative': {'id_fixo': '3607375', 'total_id': 3}, 'neutral': {'id_fixo': '3607375', 'total_id': 1}}\n"
          ]
        }
      ],
      "source": [
        "def reduceByKey1(x, y):\n",
        "    # x e y são os IDs que precisam ser somados\n",
        "    return x + y\n",
        "\n",
        "# Exemplo de dados\n",
        "data = [('positive', 1), ('negative', 2), ('positive', 3), ('neutral', 1), ('negative', 1)]\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# Inicializa um dicionário para armazenar a soma dos IDs por sentimento\n",
        "sentiment_sums = defaultdict(int)\n",
        "\n",
        "# Inicializa um dicionário para armazenar o ID fixo associado ao sentimento\n",
        "sentiment_ids = defaultdict(lambda: \"3607375\")\n",
        "\n",
        "# Percorre os dados e acumula os IDs\n",
        "for sentiment, id in data:\n",
        "    sentiment_sums[sentiment] = reduceByKey1(sentiment_sums[sentiment], id)\n",
        "\n",
        "# Exibe o resultado com o ID fixo associado ao sentimento\n",
        "result = {sentiment: {'id_fixo': sentiment_ids[sentiment], 'total_id': total}\n",
        "          for sentiment, total in sentiment_sums.items()}\n",
        "\n",
        "# Exibe o resultado\n",
        "print(result)  # {'positive':\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAuatGL8GbzK"
      },
      "source": [
        "## Aplicação do map/reduce e visualização do resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySVIb2oYGbzK",
        "outputId": "85bb7e38-ba40-4e85-8470-46de90b7f84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+-------+\n",
            "|sentiment| id|id_fixo|\n",
            "+---------+---+-------+\n",
            "| positive|  1|3607375|\n",
            "| negative|  2|3607375|\n",
            "| positive|  3|3607375|\n",
            "|  neutral|  1|3607375|\n",
            "| negative|  1|3607375|\n",
            "+---------+---+-------+\n",
            "\n",
            "Row(sentiment='positive', total_id=4)\n",
            "Row(sentiment='neutral', total_id=1)\n",
            "Row(sentiment='negative', total_id=3)\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MapReduce Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Exemplo de dados\n",
        "data = [\n",
        "    ('positive', 1),\n",
        "    ('negative', 2),\n",
        "    ('positive', 3),\n",
        "    ('neutral', 1),\n",
        "    ('negative', 1)\n",
        "]\n",
        "\n",
        "# Criação do DataFrame\n",
        "df = spark.createDataFrame(data, ['sentiment', 'id'])\n",
        "\n",
        "# Adicionando a coluna \"id_fixo\" com o valor fixo \"3607375\"\n",
        "df_with_id = df.withColumn('id_fixo', F.lit(\"3607375\"))\n",
        "\n",
        "# Exibindo o DataFrame com o ID fixo\n",
        "df_with_id.show()\n",
        "\n",
        "# Aplicando MapReduce: agrupando por 'sentiment' e somando os IDs\n",
        "result = df_with_id.groupBy('sentiment').agg(F.sum('id').alias('total_id'))\n",
        "\n",
        "# Coletando os resultados\n",
        "collected_results = result.collect()\n",
        "\n",
        "# Exibindo os resultados\n",
        "for row in collected_results:\n",
        "    print(row)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q18UlPvJGbzL"
      },
      "source": [
        "# Questão 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPSTua20GbzL"
      },
      "source": [
        "## Criar funções de MAP:\n",
        "- Criar função para mapear o \"sentiment\" como chave e uma tupla com a soma das palavras de cada texto como valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QYAZziKGbzL",
        "outputId": "0c3f2ced-b4b4-4142-e0d8-a0ca17a444da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('3607375', 'positive', 4), ('3607375', 'negative', 6), ('3607375', 'neutral', 5), ('3607375', 'positive', 3)]\n"
          ]
        }
      ],
      "source": [
        "def map2(x):\n",
        "    # x é uma tupla no formato (sentiment, text)\n",
        "    sentiment = x[0]  # O sentimento é o primeiro elemento\n",
        "    text = x[1]      # O texto é o segundo elemento\n",
        "\n",
        "    # Contamos o número de palavras no texto\n",
        "    word_count = len(text.split())  # Divide o texto em palavras e conta\n",
        "\n",
        "    # Retorna uma tupla com o ID fixo, o sentimento e a contagem de palavras\n",
        "    return (\"3607375\", sentiment, word_count)\n",
        "\n",
        "# Exemplo de dados\n",
        "data = [\n",
        "    ('positive', 'I love this product!'),\n",
        "    ('negative', 'This is the worst experience ever.'),\n",
        "    ('neutral', 'It was okay, nothing special.'),\n",
        "    ('positive', 'Absolutely fantastic service!')\n",
        "]\n",
        "\n",
        "# Aplicando a função map2 a cada elemento dos dados\n",
        "mapped_results = [map2(item) for item in data]\n",
        "\n",
        "# Exibindo os resultados mapeados\n",
        "print(mapped_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFCqo8ahGbzL"
      },
      "source": [
        "## Cria funções de REDUCE:\n",
        "\n",
        "- Criar função de reduce para somar o numero de palavras de cada texto português e inglês por \"sentiment\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whQ2n_cAGbzL",
        "outputId": "c4ebb636-580a-4dc7-f3f9-ec515e76f67a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados com o ID fixo '3607375':\n",
            "('3607375', 'positivo', 'Eu amo aprender novas coisas.')\n",
            "('3607375', 'negativo', 'Eu detesto quando as coisas não dão certo.')\n",
            "('3607375', 'positivo', 'A vida é maravilhosa.')\n",
            "('3607375', 'negativo', 'Estou muito frustrado com o que aconteceu.')\n",
            "\n",
            "Resultado final após a redução:\n",
            "{'negativo': 15, 'positivo': 9}\n"
          ]
        }
      ],
      "source": [
        "from functools import reduce\n",
        "from itertools import groupby\n",
        "\n",
        "# Função de redução para somar o número de palavras\n",
        "def reduceByKey2(x, y):\n",
        "    # Conta o número de palavras no texto x\n",
        "    palavras_x = len(x.split())\n",
        "\n",
        "    # Conta o número de palavras no texto y\n",
        "    palavras_y = len(y.split())\n",
        "\n",
        "    # Retorna a soma das palavras de ambos os textos\n",
        "    return palavras_x + palavras_y\n",
        "\n",
        "# Dados de exemplo, onde cada tupla é ('sentimento', 'texto')\n",
        "dados = [\n",
        "    (\"positivo\", \"Eu amo aprender novas coisas.\"),\n",
        "    (\"negativo\", \"Eu detesto quando as coisas não dão certo.\"),\n",
        "    (\"positivo\", \"A vida é maravilhosa.\"),\n",
        "    (\"negativo\", \"Estou muito frustrado com o que aconteceu.\"),\n",
        "]\n",
        "\n",
        "# Adicionando o ID fixo \"3607375\" para cada item\n",
        "id_fixo = \"3607375\"\n",
        "dados_com_id = [(id_fixo, sentimento, texto) for sentimento, texto in dados]\n",
        "\n",
        "# Exibindo os dados com o ID\n",
        "print(\"Dados com o ID fixo '3607375':\")\n",
        "for item in dados_com_id:\n",
        "    print(item)\n",
        "\n",
        "# Agora vamos agrupar os dados por sentimento e aplicar a função de redução para contar as palavras\n",
        "# Ordenar os dados pelo sentimento (para usar o groupby corretamente)\n",
        "dados_com_id.sort(key=lambda x: x[1])  # Ordenando pela chave \"sentimento\"\n",
        "\n",
        "# Agrupar os dados por sentimento\n",
        "resultados = {}\n",
        "for chave, grupo in groupby(dados_com_id, key=lambda x: x[1]):\n",
        "    textos = [item[2] for item in grupo]  # Coleta os textos associados ao sentimento\n",
        "    # Aplica a função de redução para contar o número total de palavras\n",
        "    total_palavras = reduce(reduceByKey2, textos)\n",
        "    resultados[chave] = total_palavras\n",
        "\n",
        "# Exibe o resultado\n",
        "print(\"\\nResultado final após a redução:\")\n",
        "print(resultados)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw8DrRVvGbzL"
      },
      "source": [
        "## Aplicação do map/reduce e visualização do resultado\n",
        "\n",
        "1. Aplicar o map/reduce no seu dataframe spark e realizar o collect() ao final\n",
        "2. Selecionar os dados referentes aos textos negativos para realizar a subtração.\n",
        "3. Realizar a subtração das contagens de palavras dos textos negativos para obter o resultado final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCWlGHFZGbzL",
        "outputId": "ca9cdda5-38cb-44a6-ec70-0fb0820bcfc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------------------------------+-------+\n",
            "|sentiment|text                                      |id     |\n",
            "+---------+------------------------------------------+-------+\n",
            "|positivo |Eu amo aprender novas coisas.             |3607375|\n",
            "|negativo |Eu detesto quando as coisas não dão certo.|3607375|\n",
            "|positivo |A vida é maravilhosa.                     |3607375|\n",
            "|negativo |Estou muito frustrado com o que aconteceu.|3607375|\n",
            "+---------+------------------------------------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lit, udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# Iniciar a sessão do Spark\n",
        "spark = SparkSession.builder.appName(\"MapReduceTextExample\").getOrCreate()\n",
        "\n",
        "# Dados de exemplo\n",
        "dados = [\n",
        "    (\"positivo\", \"Eu amo aprender novas coisas.\"),\n",
        "    (\"negativo\", \"Eu detesto quando as coisas não dão certo.\"),\n",
        "    (\"positivo\", \"A vida é maravilhosa.\"),\n",
        "    (\"negativo\", \"Estou muito frustrado com o que aconteceu.\"),\n",
        "]\n",
        "\n",
        "# Criar DataFrame do Spark\n",
        "df = spark.createDataFrame(dados, [\"sentiment\", \"text\"])\n",
        "\n",
        "# Adicionar a coluna \"id\" com o valor fixo \"3607375\"\n",
        "df_with_id = df.withColumn(\"id\", lit(\"3607375\"))\n",
        "\n",
        "# Exibir o DataFrame com a nova coluna \"id\"\n",
        "df_with_id.show(truncate=False)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
